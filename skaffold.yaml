apiVersion: skaffold/v3
kind: Config
metadata:
  name: swi-k8s-opentelemetry-collector
build:
  artifacts:
    - image: swi-k8s-opentelemetry-collector
      docker:
        dockerfile: build/docker/Dockerfile
    - image: integration-test
      docker:
        dockerfile: build/docker/IntegrationTest.Dockerfile
        buildArgs: 
          CI: "{{ .CI }}"
  local:
    push: false
manifests:
  kustomize:
    paths:
      - tests/deploy/tests
    buildArgs:
      - --load-restrictor LoadRestrictionsNone
resourceSelector:
  allow:
    # let skaffold to manager CRDs in local k8s
    - groupKind: "OpenTelemetryCollector.opentelemetry.io"
      image: [".*"]
      labels: [".*"]
    - groupKind: "PodMonitor.monitoring.coreos.com"
      image: [".*"]
      labels: [".*"]
    - groupKind: "ServiceMonitor.monitoring.coreos.com"
      image: [".*"]
      labels: [".*"]
deploy:
  kubectl: 
    defaultNamespace: test-namespace
  helm:
    releases:
      - name: timeseries-mock-service
        chartPath: tests/deploy/timeseries-mock-service
        namespace: test-namespace
        createNamespace: true
        upgradeOnChange: true
      - name: swi-k8s-opentelemetry-collector
        chartPath: deploy/helm
        namespace: test-namespace
        createNamespace: true
        setValues:
          kube-state-metrics:
            enabled: false
          cluster:
            name: "cluster name"
            uid: "cluster-uid-123456789"
          otel:
            endpoint: timeseries-mock-service:9082
            tls_insecure: true
            # OTEL collector requires the SOLARWINDS_API_TOKEN env variable to be set to some not empty string
            api_token: "not_set"
            image:
              repository: "swi-k8s-opentelemetry-collector"
              tag: ""
              pullPolicy: "Never"
            node_collector:
              managedByOperator: true
              sending_queue:
                persistent_storage:
                  enabled: true
            metrics:
              enabled: false
              prometheus_check: false
              sending_queue:
                offload_to_disk: true
              prometheus:
                scrape_interval: "15s"
              kube-state-metrics:
                scrape_interval: "15s"
              control_plane:
                controller_manager:
                  enabled: false
                etcd:
                  enabled: false
              k8s_instrumentation:
                annotations:
                  # excluded annotations:
                  # * kubectl.kubernetes.io/last-applied-configuration - deployed by kubectl, contains full config for each resource
                  # * cni.projectcalico.org/ - deployed in CI system (k3s)
                  excludePattern: "(kubectl\\.kubernetes\\.io/last-applied-configuration)|(cni\\.projectcalico\\.org/.*)|(deployment\\.kubernetes\\.io/revision)|(deprecated\\.daemonset\\.template\\.generation)"
                labels:
                  # excluded labels:
                  # * skaffold.dev/ - deployed by skaffold, contains unique ids so it must be excluded
                  excludePattern: "skaffold\\.dev/.*"
              autodiscovery:
                prometheusEndpoints: 
                  customTransformations:
                    counterToRate:
                      - k8s.otelcol_exporter_sent_metric_points
                      - k8s.otelcol_exporter_sent_log_records
                  filter:
                    exclude:
                      match_type: regexp
                      metric_names:
                        - k8s.otelcol_processor.*
                  podMonitors:
                    rules:
                      - rule: labels["app"] == "test-deployment"
                        metrics_path: "/custom_metrics"
                        endpoint_port: 8081
                prefix: ""
            events:
              enabled: false
              sending_queue:
                offload_to_disk: true
            manifests:
              enabled: true
              pull_every: 1m
            logs:
              # journal on Docker Desktop is not supported
              enabled: false
              journal: false
              filter:
                log_record:
                  - resource.attributes["k8s.namespace.name"] == "test-namespace"
          certmanager:
            enabled: true
          operator:
            enabled: true
          ebpfNetworkMonitoring:
            enabled: false
          prometheusCRDs:
            install: true
        upgradeOnChange: true
      
      # Deploy prometheus for development purposes. Metrics prefixed with `output_` contains metrics produced by the agent
      - name: monitoring
        remoteChart: prometheus
        namespace: test-namespace
        createNamespace: true
        repo: https://prometheus-community.github.io/helm-charts
        version: 19.7.2
        setValues:
          alertmanager.enabled: false
          prometheus-node-exporter.enabled: false
          prometheus-pushgateway.enabled: false
          kube-state-metrics.enabled: false
          server:
            nodeSelector:
              "kubernetes\\.io\\/os": linux
  kubeContext: docker-desktop
portForward:
- resourceType: service
  resourceName: timeseries-mock-service
  namespace: test-namespace
  port: 8088
- resourceType: service
  resourceName: monitoring-prometheus-server
  namespace: test-namespace
  port: 80
  localPort: 8080
profiles:
  - name: test-cluster
    build:
      artifacts:
        - image: swi-k8s-opentelemetry-collector
          docker:
            dockerfile: build/docker/Dockerfile
      local:
        push: true
    patches:
    - op: remove
      path: /deploy/helm/releases/0
    - op: replace
      path: /deploy/helm/releases/0/namespace
      value: "{{.TEST_CLUSTER_NAMESPACE}}"
    - op: replace
      path: /deploy/helm/releases/0/name
      value: "{{.TEST_CLUSTER_RELEASE_NAME}}"
    - op: replace
      path: /portForward/0/namespace
      value: "{{.TEST_CLUSTER_NAMESPACE}}"
    - op: replace
      path: /portForward/1/namespace
      value: "{{.TEST_CLUSTER_NAMESPACE}}"
    - op: replace
      path: /portForward/1/resourceName
      value: "{{.TEST_CLUSTER_RELEASE_NAME}}-prometheus-server"
    - op: replace
      path: /deploy/kubectl/defaultNamespace
      value: "{{.TEST_CLUSTER_NAMESPACE}}"
    - op: remove
      path: /manifests/kustomize/paths/0
    - op: replace
      path: /deploy/helm/releases/1/namespace
      value: "{{.TEST_CLUSTER_NAMESPACE}}"
    - op: replace
      path: /deploy/helm/releases/1/name
      value: "{{.TEST_CLUSTER_RELEASE_NAME}}-prometheus"
    - op: replace
      path: /deploy/kubeContext
      value: "<your kube context here>"
  - name: ci
    activation:
      - env: CI=true
    build:
      local:
        push: false
        useBuildkit: true
        concurrency: 0
    test:
      - image: swi-k8s-opentelemetry-collector
        structureTests:
          - './build/docker/structure-test.yaml'
      - image: swi-k8s-opentelemetry-collector-tests
        custom:
          - command: docker run --rm $IMAGE
            timeoutSeconds: 300
            dependencies:
              paths:
                - ./src/**
    patches:
    - op: remove
      path: /deploy/helm/releases/2
    - op: remove
      path: /portForward/1
    - op: add
      path: /build/artifacts/-
      value:
        image: swi-k8s-opentelemetry-collector-tests
        docker:
          dockerfile: build/docker/Dockerfile
          target: tests
    deploy:
      kubeContext: default
  - name: ci-helm-e2e
    patches:
      - op: remove
        path: /build/artifacts/0
      - op: remove
        path: /deploy/helm/releases/1/setValues/otel.image.repository
      - op: remove
        path: /deploy/helm/releases/1/setValues/otel.image.tag
    build:
      local:
        push: false
        useBuildkit: true
        concurrency: 0
    deploy:
      # `default` is k3s default context name
      kubeContext: default
