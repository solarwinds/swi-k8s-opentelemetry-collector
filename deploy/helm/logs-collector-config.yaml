exporters:
  otlp:
    endpoint: ${OTEL_ENVOY_ADDRESS}
    tls:
      insecure: ${OTEL_ENVOY_ADDRESS_TLS_INSECURE}
    headers:
      "Authorization": "Bearer ${SOLARWINDS_API_TOKEN}"
extensions:
  file_storage:
{{ toYaml .Values.otel.logs.filestorage | indent 4 }}
  health_check: {}
  memory_ballast:
{{ toYaml .Values.otel.logs.memory_ballast | indent 4 }}
  k8s_observer:
    auth_type: serviceAccount
    node: ${NODE_NAME}
processors:
  k8sattributes:
    auth_type: "serviceAccount"
    passthrough: false
    filter:
      node_from_env_var: NODE_NAME
    extract:
      metadata:
        - k8s.deployment.name
        - k8s.replicaset.name
        - k8s.daemonset.name
        - k8s.job.name
        - k8s.cronjob.name
        - k8s.statefulset.name
      labels:
        - key_regex: (.*)
          tag_name: k8s.pod.labels.$$1
          from: pod
    pod_association:
      - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
  memory_limiter:
{{ toYaml .Values.otel.logs.memory_limiter | indent 4 }}

{{- if .Values.otel.logs.filter }}
  # For more all the options about the filtering see https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor
  filter:
    logs:
{{ toYaml .Values.otel.logs.filter | indent 6 }}
{{- end }}

  groupbyattrs/all:
    keys:
      - k8s.container.name
      - k8s.namespace.name
      - k8s.pod.name
      - k8s.pod.uid
      - host.hostname
      - service.name


  resource/container:
    attributes:

      - key: sw.k8s.log.type
        value: container
        action: insert

      # Collector and Manifest version
      - key: sw.k8s.agent.manifest.version
        value: ${MANIFEST_VERSION}
        action: insert

      - key: sw.k8s.agent.app.version
        value: ${APP_VERSION}
        action: insert

      # Cluster
      - key: sw.k8s.cluster.uid
        value: ${CLUSTER_UID}
        action: insert

      - key: k8s.cluster.name
        value: ${CLUSTER_NAME}
        action: insert

      # Node
      - key: k8s.node.name
        value: ${NODE_NAME}
        action: insert

  resource/journal:
    attributes:

      - key: sw.k8s.log.type
        value: journal
        action: insert

      # Collector and Manifest version
      - key: sw.k8s.agent.manifest.version
        value: ${MANIFEST_VERSION}
        action: insert

      - key: sw.k8s.agent.app.version
        value: ${APP_VERSION}
        action: insert

      # Cluster
      - key: sw.k8s.cluster.uid
        value: ${CLUSTER_UID}
        action: insert

      - key: k8s.cluster.name
        value: ${CLUSTER_NAME}
        action: insert

      # Node
      - key: k8s.node.name
        value: ${NODE_NAME}
        action: insert
  transform/syslogify:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          - set( attributes["syslog.facility"], 1 )
          - set( attributes["syslog.version"], 1 )
          - set( attributes["host.hostname"], attributes["k8s.pod.name"])
          - set( attributes["service.name"], attributes["k8s.container.name"])
          - set( attributes["syslog.procid"], attributes["run_id"])
          - set( attributes["syslog.msgid"], attributes["stream"])

  batch:
{{ toYaml .Values.otel.logs.batch | indent 4 }}

receivers:
  kubeletstats:
    collection_interval: 60s
    auth_type: "serviceAccount"
    endpoint: ${NODE_IP}:10250
    insecure_skip_verify: true
    metric_groups:
      - container
      - pod
      - node
  hostmetrics:
    collection_interval: 60s
    scrapers:
      cpu:
      disk:
      #filesystem:
      memory:
      network:
      load:
      paging:
      processes:
  receiver_creator:
    watch_observers: 
      - k8s_observer
    receivers:
      prometheus_simple:
        rule: type == "pod" && annotations["prometheus.io/scrape"] == "true"
        config:
          collection_interval: 60s
          metrics_path: '`"prometheus.io/path" in annotations ? annotations["prometheus.io/path"] : "/metrics"`'
          endpoint: '`endpoint`:`"prometheus.io/port" in annotations ? annotations["prometheus.io/port"] : 9090`'
  journald:
    directory: /run/log/journal
    units:
      - kubelet
      - docker
      - containerd
  filelog:
    include: [ /var/log/pods/*/*/*.log ]
    # Exclude collector container's logs. The file format is /var/log/pods/<namespace_name>_<pod_name>_<pod_uid>/<container_name>/<run_id>.log
    exclude: [ "/var/log/pods/${POD_NAMESPACE}_${POD_NAME}*_*/swi-opentelemetry-collector/*.log" ]
    start_at: {{ .Values.otel.logs.receiver.start_at }}
    include_file_path: true
    include_file_name: false
    storage: file_storage
    max_log_size: {{ .Values.otel.logs.receiver.max_log_size }}
    max_concurrent_files: {{ .Values.otel.logs.receiver.max_concurrent_files }}
    fingerprint_size: {{ .Values.otel.logs.receiver.fingerprint_size }}
    encoding: {{ .Values.otel.logs.receiver.encoding }}
    poll_interval: {{ .Values.otel.logs.receiver.poll_interval }}
    operators:
      # Find out which format is used by kubernetes
      - type: router
        id: get-format
        routes:
          - output: parser-docker
            expr: 'body matches "^\\{"'
          - output: parser-crio
            expr: 'body matches "^[^ Z]+ "'
          - output: parser-containerd
            expr: 'body matches "^[^ Z]+Z"'
      # Parse CRI-O format
      - type: regex_parser
        id: parser-crio
        regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$'
        output: merge-cri-lines
        parse_to: body
        timestamp:
          parse_from: body.time
          layout_type: gotime
          layout: '2006-01-02T15:04:05.999999999-07:00'
      # Parse CRI-Containerd format
      - type: regex_parser
        id: parser-containerd
        regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$'
        output: merge-cri-lines
        parse_to: body
        timestamp:
          parse_from: body.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      # Parse Docker format
      - type: json_parser
        id: parser-docker
        parse_to: body
        output: merge-docker-lines
        timestamp:
          parse_from: body.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'

      # Merge log lines split by Docker logging driver.
      - type: recombine
        id: merge-docker-lines
        source_identifier: attributes["log.file.path"]
        output: merge-multiline-logs
        combine_field: body.log
        combine_with: ""
        is_last_entry: body.log matches "\n$"

      # Merge log lines split by CRI logging drivers.
      - type: recombine
        id: merge-cri-lines
        source_identifier: attributes["log.file.path"]
        output: merge-multiline-logs
        combine_field: body.log
        combine_with: ""
        is_last_entry: body.logtag == "F"
        overwrite_with: newest

      # Merges incoming log records into multiline logs.
      - type: recombine
        id: merge-multiline-logs
        output: extract-metadata-from-filepath
        source_identifier: attributes["log.file.path"]
        combine_field: body.log
        combine_with: ""
        is_first_entry: body.log matches "^\\[?\\d{4}-\\d{1,2}-\\d{1,2}.\\d{2}:\\d{2}:\\d{2}.*"

      # Extract metadata from file path
      - type: regex_parser
        id: extract-metadata-from-filepath
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$'
        parse_from: attributes["log.file.path"]

      # Rename attributes
      - type: move
        id: move-attributes
        from: body.stream
        to: attributes["stream"]
      - type: move
        from: attributes.container_name
        to: attributes["k8s.container.name"]
      - type: move
        from: attributes.namespace
        to: attributes["k8s.namespace.name"]
      - type: move
        from: attributes.pod_name
        to: attributes["k8s.pod.name"]
      - type: move
        from: attributes.run_id
        to: attributes["run_id"]
      - type: move
        from: attributes.uid
        to: attributes["k8s.pod.uid"]
      - type: remove
        field: attributes["log.file.path"]
      - type: remove
        field: body.time
      - type: move
        from: body.log
        to: body

service:
  extensions:
    - file_storage
    - health_check
    - memory_ballast
    - k8s_observer
  pipelines:
{{- if .Values.otel.logs.container }}
    logs:
      exporters:
        - otlp
      processors:
        - memory_limiter
{{- if .Values.otel.logs.filter }}
        - filter
{{- end }}
        - transform/syslogify
        - groupbyattrs/all
        - resource/container
        - batch
      receivers:
        - filelog
{{- end }}
{{- if .Values.otel.logs.journal }}
    logs/2:
      exporters:
        - otlp
      processors:
        - memory_limiter
        - groupbyattrs/all
        - resource/journal
        - batch
      receivers:
        - journald
{{- end }}
    metrics:
      exporters:
        - otlp
      processors:
        - memory_limiter
        - groupbyattrs/all
        - k8sattributes
        - batch
      receivers:
        - kubeletstats
        - hostmetrics
        - receiver_creator
  telemetry:
{{- if .Values.otel.logs.telemetry.logs.enabled }}
    logs:
      level: {{ .Values.otel.logs.telemetry.logs.level }}
{{- end }}
{{- if .Values.otel.logs.telemetry.metrics.enabled }}
    metrics:
      address: {{ .Values.otel.logs.telemetry.metrics.address }}
{{- end }}
