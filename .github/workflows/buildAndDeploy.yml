name: Build and Deploy

on:
  push:
    branches: 
      - master
      - release/**

  pull_request:
    branches: 
      - master
      - release/**

  release:
    types: [published]

  workflow_dispatch:

env:
  DOCKERHUB_IMAGE: solarwinds/swi-opentelemetry-collector

jobs:
  build_and_test:
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.generate-tag.outputs.value }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Deploy skaffold
        uses: ./.github/actions/deploy-skaffold

      - name: Generate docker image tag
        id: generate-tag
        run: echo "::set-output name=value::v${{ github.run_number }}-$(git rev-parse --short HEAD)"

      - name: Build
        run: skaffold build --file-output=/tmp/tags.json --tag ${{ steps.generate-tag.outputs.value }}

      - name: Test
        run: skaffold test --build-artifacts=/tmp/tags.json

      - name: Deploy kubernetes
        uses: ./.github/actions/deploy-kubernetes

      - name: Add dependency chart repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add opencost https://opencost.github.io/opencost-helm-chart

      - name: Deploy services using Skaffold
        run: skaffold deploy --build-artifacts=/tmp/tags.json

      - name: Run integration tests
        uses: ./.github/actions/run-integration-tests
  
  build_and_test_windows:
    runs-on: windows-2022
    if: github.event_name == 'release' && github.event.action == 'published' && !contains(github.ref, 'swo-k8s-collector')
    outputs:
      image_tag: ${{ steps.generate-tag.outputs.value }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate docker image tag
        id: generate-tag
        run: echo "::set-output name=value::v${{ github.run_number }}-$(git rev-parse --short HEAD)"

      - name: Build
        run: |
          docker build -t swi-k8s-opentelemetry-collector:${{ steps.generate-tag.outputs.value }}-nanoserver-ltsc2022 -f build/docker/Dockerfile.Windows-2022 . 
          
      - name: CP assets
        run: |
          docker create --name assets swi-k8s-opentelemetry-collector:${{ steps.generate-tag.outputs.value }}-nanoserver-ltsc2022
          docker cp assets:/swi-otelcol.exe swi-otelcol.exe
          docker cp assets:/wrapper.exe wrapper.exe

      - name: Build 2019
        run: |
          docker build -t swi-k8s-opentelemetry-collector:${{ steps.generate-tag.outputs.value }}-nanoserver-ltsc2019 --build-arg WINBASE=mcr.microsoft.com/windows/nanoserver:ltsc2019 -f build/docker/Dockerfile.Windows-Runtime . 

      - name: Save image
        if: github.event_name == 'release' && github.event.action == 'published' && !contains(github.ref, 'swo-k8s-collector')
        run: |
          docker save --output swi-k8s-opentelemetry-collector-windows-ltsc2022.tar swi-k8s-opentelemetry-collector:${{ steps.generate-tag.outputs.value }}-nanoserver-ltsc2022
          docker save --output swi-k8s-opentelemetry-collector-windows-ltsc2019.tar swi-k8s-opentelemetry-collector:${{ steps.generate-tag.outputs.value }}-nanoserver-ltsc2019
      
      - uses: actions/upload-artifact@v3
        if: github.event_name == 'release' && github.event.action == 'published' && !contains(github.ref, 'swo-k8s-collector')
        with:
          name: image
          path: |
            swi-k8s-opentelemetry-collector-windows-ltsc2022.tar
            swi-k8s-opentelemetry-collector-windows-ltsc2019.tar
          retention-days: 2
        

  # Verify whether Helm chart works with image published in DockerHub
  helm_e2e:
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.generate-tag.outputs.value }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Deploy skaffold
        uses: ./.github/actions/deploy-skaffold

      - name: Deploy kubernetes
        uses: ./.github/actions/deploy-kubernetes

      - name: Add dependency chart repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add opencost https://opencost.github.io/opencost-helm-chart

      - name: Build
        run: skaffold build -p=ci-helm-e2e --file-output=/tmp/tags.json

      - name: Deploy services using Skaffold
        run: skaffold deploy -p=ci-helm-e2e --build-artifacts=/tmp/tags.json
      
      - name: Run integration tests
        uses: ./.github/actions/run-integration-tests


  helm_verify:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.8.2

      - name: Add dependency chart repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add opencost https://opencost.github.io/opencost-helm-chart


      - name: Download chart dependencies before linting
        run: helm dependency build deploy/helm

      - name: Lint helm
        run: helm lint deploy/helm

      - name: Lint template
        run: helm template deploy/helm

      - name: Install Unit test plugin
        run: helm plugin install https://github.com/helm-unittest/helm-unittest.git
      
      - name: Run unit tests
        run: helm unittest deploy/helm

  helm_test_auto_update_against_last_published:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Deploy Kubernetes
        uses: ./.github/actions/deploy-kubernetes

      - name: Add dependency chart repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add opencost https://opencost.github.io/opencost-helm-chart
          helm repo add solarwinds https://helm.solarwinds.com
          helm repo update

      - name: Deploy mocks.yaml
        run: kubectl apply -f tests/deploy/base/mocks.yaml


      - name: Create Dockerfile with Helm repository
        run: |
          cat <<EOF > Dockerfile
          FROM python:3.12-alpine3.19
          WORKDIR /app
          COPY . .
          EXPOSE 5000
          CMD ["python", "-m", "http.server", "5000"]
          EOF

      - name: Package and build Helm repository image
        run: |
          helm dependency build deploy/helm
          helm package deploy/helm
          helm repo index .
          docker build -t helm-repo:latest .

      - name: Deploy Helm repository in Kubernetes cluster
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: helm-repo
          spec:
            selector:
              matchLabels:
                app: helm-repo
            replicas: 1
            template:
              metadata:
                labels:
                  app: helm-repo
              spec:
                containers:
                - name: helm-repo
                  image: helm-repo:latest
                  imagePullPolicy: Never
                  ports:
                  - containerPort: 5000
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: helm-repo
          spec:
            selector:
              app: helm-repo
            ports:
              - protocol: TCP
                port: 5000
                targetPort: 5000
            type: ClusterIP
          EOF

      - name: Deploy swo-k8s-collector Helm chart
        run: |
          helm install swo-k8s-collector solarwinds/swo-k8s-collector \
            --create-namespace \
            --namespace swo-k8s-collector \
            --set cluster.name=test-cluster \
            --set cluster.uid=test-cluster \
            --set otel.endpoint=timeseries-mock-service:9082 \
            --set prometheus.enabled=true \
            --set autoupdate.enabled=true \
            --set autoupdate.devel=true \
            --set otel.metrics.swi_endpoint_check=false \
            --set otel.metrics.prometheus_check=false \
            --set otel.metrics.resources.requests.memory=100Mi \
            --set otel.events.resources.requests.memory=100Mi \
            --set otel.logs.resources.requests.memory=100Mi

      - name: Update AutoUpdate ConfigMap to use local Helm repository
        run: |
          kubectl get configmap swo-k8s-collector-autoupdate-script -n swo-k8s-collector -o yaml > autoupdate-script.yaml
          sed -i 's|https://helm.solarwinds.com|http://helm-repo.default.svc.cluster.local:5000|' autoupdate-script.yaml
          kubectl apply -f autoupdate-script.yaml
          cat autoupdate-script.yaml

      - name: Trigger helm-autoupdate CronJob and verify
        run: |
          # Trigger the CronJob
          kubectl create job --from=cronjob/helm-autoupdate helm-autoupdate-manual-trigger -n swo-k8s-collector
          
          # Wait for the job to complete
          kubectl wait --for=condition=complete --timeout=300s job/helm-autoupdate-manual-trigger -n swo-k8s-collector
          
          # Get the job's success and failure status
          JOB_SUCCEEDED=$(kubectl get job helm-autoupdate-manual-trigger -n swo-k8s-collector -o=jsonpath='{.status.succeeded}')
          JOB_FAILED=$(kubectl get job helm-autoupdate-manual-trigger -n swo-k8s-collector -o=jsonpath='{.status.failed}')

          # Check if the job succeeded or failed
          if [ "$JOB_SUCCEEDED" == "1" ]; then
            echo "Job completed successfully."
          elif [ "$JOB_FAILED" != "" ]; then
            echo "Job failed."
            exit 1
          else
            echo "Job did not complete successfully. Status is ambiguous."
            exit 1
          fi

      - name: Trigger helm-autoupdate CronJob logs
        if: ${{ always() }}
        run: |
          kubectl logs jobs/helm-autoupdate-manual-trigger -n swo-k8s-collector --all-containers=true

  deploy_dockerhub:
    runs-on: ubuntu-latest
    needs: build_and_test
    name: Deploy to docker hub
    if: github.event_name == 'release' && github.event.action == 'published' && !contains(github.ref, 'swo-k8s-collector')
    environment:
      name: production
      url: https://hub.docker.com/repository/docker/solarwinds/swi-opentelemetry-collector
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Get image tag
        id: vars
        run: echo ::set-output name=tag::${GITHUB_REF#refs/*/}

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_CI_USER }}
          password: ${{ secrets.DOCKER_HUB_CI_PASSWORD }}
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: build/docker/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}

  deploy_dockerhub_windows:
    runs-on: windows-2022
    needs: build_and_test_windows
    name: Deploy to docker hub Windows
    if: github.event_name == 'release' && github.event.action == 'published' && !contains(github.ref, 'swo-k8s-collector')
    environment:
      name: production
      url: https://hub.docker.com/repository/docker/solarwinds/swi-opentelemetry-collector
    steps:
      - uses: actions/download-artifact@v3
        with:
          name: image

      - name: Get image tag
        id: vars
        run: echo "tag=$env:GITHUB_REF_NAME" >> $ENV:GITHUB_OUTPUT

      - name: Load image
        run: |
          docker load --input swi-k8s-opentelemetry-collector-windows-ltsc2022.tar
          docker load --input swi-k8s-opentelemetry-collector-windows-ltsc2019.tar

      - name: Tag images
        run: |
          docker tag swi-k8s-opentelemetry-collector:${{ needs.build_and_test_windows.outputs.image_tag }}-nanoserver-ltsc2022 ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2022
          docker tag swi-k8s-opentelemetry-collector:${{ needs.build_and_test_windows.outputs.image_tag }}-nanoserver-ltsc2019 ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2019

      - name: Docker login
        env:
          DOCKER_HUB_CI_PASSWORD: ${{ secrets.DOCKER_HUB_CI_PASSWORD }}
          DOCKER_HUB_CI_USER: ${{ secrets.DOCKER_HUB_CI_USER }}
        run: echo "$env:DOCKER_HUB_CI_PASSWORD" | docker login -u "$env:DOCKER_HUB_CI_USER" --password-stdin

      - name: Push as specific
        run: | 
          docker push ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2022
          docker push ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2019

      - name: Create multi-arch manifest
        run: | 
          docker manifest create ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver --amend ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2022 --amend ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver-ltsc2019

      - name: Push multi-arch manifest
        run: | 
          docker manifest push ${{ env.DOCKERHUB_IMAGE }}:${{ steps.vars.outputs.tag }}-nanoserver

